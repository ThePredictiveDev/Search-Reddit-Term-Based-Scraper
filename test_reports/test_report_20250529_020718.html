<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">test_report_20250529_020718.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">test_report_20250529_020718.html</h1>
    <p>Report generated on 29-May-2025 at 02:09:01 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">107 tests took 00:01:21.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">64 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">43 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" />
            <span class="error">14 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.12.1&#34;, &#34;Platform&#34;: &#34;Windows-10-10.0.19045-SP0&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.3.5&#34;, &#34;pluggy&#34;: &#34;1.5.0&#34;}, &#34;Plugins&#34;: {&#34;anyio&#34;: &#34;4.8.0&#34;, &#34;asyncio&#34;: &#34;0.21.1&#34;, &#34;cov&#34;: &#34;4.1.0&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;xdist&#34;: &#34;3.7.0&#34;}}, &#34;tests&#34;: {&#34;tests/test_database.py::test_database_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_database_initialization&#34;, &#34;duration&#34;: &#34;30 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_database_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;30 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_database.py::test_create_search_session&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_create_search_session&#34;, &#34;duration&#34;: &#34;25 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_create_search_session&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;25 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_database.py::test_add_mention&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_add_mention::setup&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_add_mention::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py, line 38\n  @pytest.mark.unit\n  def test_add_mention(db_manager, sample_mention):\nE       fixture &amp;#x27;sample_mention&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py:38\n&#34;}], &#34;tests/test_database.py::test_get_mentions_by_session&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_get_mentions_by_session&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_get_mentions_by_session&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;sqlalchemy.engine.base.Connection object at 0x000001BEDC8BDBB0&amp;gt;\ndialect = &amp;lt;sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x000001BEDC8BCF20&amp;gt;\ncontext = &amp;lt;sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x000001BEDC8BDAF0&amp;gt;\nstatement = &amp;lt;sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x000001BEDC8BE390&amp;gt;\nparameters = [(1, &amp;#x27;test0&amp;#x27;, None, &amp;#x27;Test post 0 about OpenAI&amp;#x27;, &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;test_user&amp;#x27;, ...)]\n\n    def _exec_single_context(\n        self,\n        dialect: Dialect,\n        context: ExecutionContext,\n        statement: Union[str, Compiled],\n        parameters: Optional[_AnyMultiExecuteParams],\n    ) -&amp;gt; CursorResult[Any]:\n        &amp;quot;&amp;quot;&amp;quot;continue the _execute_context() method for a single DBAPI\n        cursor.execute() or cursor.executemany() call.\n    \n        &amp;quot;&amp;quot;&amp;quot;\n        if dialect.bind_typing is BindTyping.SETINPUTSIZES:\n            generic_setinputsizes = context._prepare_set_input_sizes()\n    \n            if generic_setinputsizes:\n                try:\n                    dialect.do_set_input_sizes(\n                        context.cursor, generic_setinputsizes, context\n                    )\n                except BaseException as e:\n                    self._handle_dbapi_exception(\n                        e, str(statement), parameters, None, context\n                    )\n    \n        cursor, str_statement, parameters = (\n            context.cursor,\n            context.statement,\n            context.parameters,\n        )\n    \n        effective_parameters: Optional[_AnyExecuteParams]\n    \n        if not context.executemany:\n            effective_parameters = parameters[0]\n        else:\n            effective_parameters = parameters\n    \n        if self._has_events or self.engine._has_events:\n            for fn in self.dispatch.before_cursor_execute:\n                str_statement, effective_parameters = fn(\n                    self,\n                    cursor,\n                    str_statement,\n                    effective_parameters,\n                    context,\n                    context.executemany,\n                )\n    \n        if self._echo:\n            self._log_info(str_statement)\n    \n            stats = context._get_cache_stats()\n    \n            if not self.engine.hide_parameters:\n                self._log_info(\n                    &amp;quot;[%s] %r&amp;quot;,\n                    stats,\n                    sql_util._repr_params(\n                        effective_parameters,\n                        batches=10,\n                        ismulti=context.executemany,\n                    ),\n                )\n            else:\n                self._log_info(\n                    &amp;quot;[%s] [SQL parameters hidden due to hide_parameters=True]&amp;quot;,\n                    stats,\n                )\n    \n        evt_handled: bool = False\n        try:\n            if context.execute_style is ExecuteStyle.EXECUTEMANY:\n                effective_parameters = cast(\n                    &amp;quot;_CoreMultiExecuteParams&amp;quot;, effective_parameters\n                )\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_executemany:\n                        if fn(\n                            cursor,\n                            str_statement,\n                            effective_parameters,\n                            context,\n                        ):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_executemany(\n                        cursor,\n                        str_statement,\n                        effective_parameters,\n                        context,\n                    )\n            elif not effective_parameters and context.no_parameters:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute_no_params:\n                        if fn(cursor, str_statement, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_execute_no_params(\n                        cursor, str_statement, context\n                    )\n            else:\n                effective_parameters = cast(\n                    &amp;quot;_CoreSingleExecuteParams&amp;quot;, effective_parameters\n                )\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute:\n                        if fn(\n                            cursor,\n                            str_statement,\n                            effective_parameters,\n                            context,\n                        ):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n&amp;gt;                   self.dialect.do_execute(\n                        cursor, str_statement, effective_parameters, context\n                    )\n\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1964: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x000001BEDC8BCF20&amp;gt;\ncursor = &amp;lt;sqlite3.Cursor object at 0x000001BEDC9371C0&amp;gt;\nstatement = &amp;#x27;INSERT INTO reddit_mentions (session_id, reddit_id, post_type, title, content, author, subreddit, url, score, num_com...ratio, created_utc, scraped_at, sentiment_score, relevance_score) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&amp;#x27;\nparameters = (1, &amp;#x27;test0&amp;#x27;, None, &amp;#x27;Test post 0 about OpenAI&amp;#x27;, &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;test_user&amp;#x27;, ...)\ncontext = &amp;lt;sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x000001BEDC8BDAF0&amp;gt;\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n&amp;gt;       cursor.execute(statement, parameters)\nE       sqlite3.IntegrityError: NOT NULL constraint failed: reddit_mentions.post_type\n\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\default.py:942: IntegrityError\n\nThe above exception was the direct cause of the following exception:\n\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC8BCEC0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 36, 571509), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_get_mentions_by_session(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test retrieving mentions by session.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add multiple mentions\n        for mention in sample_mentions_list:\n            mention_data = mention.copy()\n            mention_data[&amp;#x27;session_id&amp;#x27;] = session_id\n&amp;gt;           db_manager.add_mention(mention_data)\n\ntests\\test_database.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ndatabase\\models.py:97: in add_mention\n    db.commit()\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:2032: in commit\n    trans.commit(_to_root=True)\n&amp;lt;string&amp;gt;:2: in commit\n    ???\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\state_changes.py:139: in _go\n    ret_value = fn(self, *arg, **kw)\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:1313: in commit\n    self._prepare_impl()\n&amp;lt;string&amp;gt;:2: in _prepare_impl\n    ???\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\state_changes.py:139: in _go\n    ret_value = fn(self, *arg, **kw)\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:1288: in _prepare_impl\n    self.session.flush()\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:4353: in flush\n    self._flush(objects)\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:4488: in _flush\n    with util.safe_reraise():\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\util\\langhelpers.py:146: in __exit__\n    raise exc_value.with_traceback(exc_tb)\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\session.py:4449: in _flush\n    flush_context.execute()\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\unitofwork.py:466: in execute\n    rec.execute(self)\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\unitofwork.py:642: in execute\n    util.preloaded.orm_persistence.save_obj(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\persistence.py:93: in save_obj\n    _emit_insert_statements(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\orm\\persistence.py:1233: in _emit_insert_statements\n    result = connection.execute(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1416: in execute\n    return meth(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\sql\\elements.py:523: in _execute_on_connection\n    return connection._execute_clauseelement(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1638: in _execute_clauseelement\n    ret = self._execute_context(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1843: in _execute_context\n    return self._exec_single_context(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1983: in _exec_single_context\n    self._handle_dbapi_exception(\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:2352: in _handle_dbapi_exception\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:1964: in _exec_single_context\n    self.dialect.do_execute(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x000001BEDC8BCF20&amp;gt;\ncursor = &amp;lt;sqlite3.Cursor object at 0x000001BEDC9371C0&amp;gt;\nstatement = &amp;#x27;INSERT INTO reddit_mentions (session_id, reddit_id, post_type, title, content, author, subreddit, url, score, num_com...ratio, created_utc, scraped_at, sentiment_score, relevance_score) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&amp;#x27;\nparameters = (1, &amp;#x27;test0&amp;#x27;, None, &amp;#x27;Test post 0 about OpenAI&amp;#x27;, &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;test_user&amp;#x27;, ...)\ncontext = &amp;lt;sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x000001BEDC8BDAF0&amp;gt;\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n&amp;gt;       cursor.execute(statement, parameters)\nE       sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) NOT NULL constraint failed: reddit_mentions.post_type\nE       [SQL: INSERT INTO reddit_mentions (session_id, reddit_id, post_type, title, content, author, subreddit, url, score, num_comments, upvote_ratio, created_utc, scraped_at, sentiment_score, relevance_score) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\nE       [parameters: (1, &amp;#x27;test0&amp;#x27;, None, &amp;#x27;Test post 0 about OpenAI&amp;#x27;, &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;test_user&amp;#x27;, &amp;#x27;technology&amp;#x27;, &amp;#x27;https://reddit.com/r/technology/comments/test123&amp;#x27;, 10, 15, None, &amp;#x27;2025-05-28 20:37:36.571509&amp;#x27;, &amp;#x27;2025-05-28 20:37:36.571509&amp;#x27;, -0.5, 0.8)]\nE       (Background on this error at: https://sqlalche.me/e/20/gkpj)\n\n..\\..\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\default.py:942: IntegrityError\n&#34;}], &#34;tests/test_database.py::test_update_session_status&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_update_session_status&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_update_session_status&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC966780&amp;gt;\n\n    @pytest.mark.unit\n    def test_update_session_status(db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test updating session status.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Update to completed\n&amp;gt;       db_manager.update_session_status(session_id, &amp;quot;completed&amp;quot;)\nE       AttributeError: &amp;#x27;DatabaseManager&amp;#x27; object has no attribute &amp;#x27;update_session_status&amp;#x27;\n\ntests\\test_database.py:81: AttributeError\n&#34;}], &#34;tests/test_database.py::test_get_session_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_get_session_statistics&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_get_session_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC964200&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 37, 621524), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_get_session_statistics(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test getting session statistics.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add mentions with different scores\n        for mention in sample_mentions_list:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:95: TypeError\n&#34;}], &#34;tests/test_database.py::test_search_mentions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_search_mentions&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_search_mentions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDDB40EF0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 37, 646524), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_search_mentions(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test searching mentions with filters.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add mentions\n        for mention in sample_mentions_list:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:112: TypeError\n&#34;}], &#34;tests/test_database.py::test_get_trending_subreddits&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_get_trending_subreddits&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_get_trending_subreddits&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC966840&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 37, 671532), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_get_trending_subreddits(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test getting trending subreddits.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add mentions from different subreddits\n        for mention in sample_mentions_list:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:135: TypeError\n&#34;}], &#34;tests/test_database.py::test_get_sentiment_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_get_sentiment_distribution&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_get_sentiment_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDDB41910&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 37, 696526), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_get_sentiment_distribution(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test getting sentiment distribution.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add mentions with various sentiments\n        for mention in sample_mentions_list:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:154: TypeError\n&#34;}], &#34;tests/test_database.py::test_get_time_series_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_get_time_series_data&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_get_time_series_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC9F8B90&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 37, 722524), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_get_time_series_data(db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test getting time series data.&amp;quot;&amp;quot;&amp;quot;\n        session_id = db_manager.create_search_session(&amp;quot;test&amp;quot;)\n    \n        # Add mentions with different timestamps\n        for mention in sample_mentions_list:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:175: TypeError\n&#34;}], &#34;tests/test_database.py::test_cleanup_old_sessions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_cleanup_old_sessions&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_cleanup_old_sessions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC9FAC00&amp;gt;\n\n    @pytest.mark.unit\n    def test_cleanup_old_sessions(db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test cleaning up old sessions.&amp;quot;&amp;quot;&amp;quot;\n        # Create old session\n        old_session_id = db_manager.create_search_session(&amp;quot;old_test&amp;quot;)\n    \n        # Manually set old timestamp\n&amp;gt;       with db_manager.Session() as session:\nE       AttributeError: &amp;#x27;DatabaseManager&amp;#x27; object has no attribute &amp;#x27;Session&amp;#x27;\n\ntests\\test_database.py:195: AttributeError\n&#34;}], &#34;tests/test_database.py::test_database_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_database_error_handling&#34;, &#34;duration&#34;: &#34;16 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_database_error_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;16 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC9A64B0&amp;gt;\n\n    @pytest.mark.unit\n    def test_database_error_handling(db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test database error handling.&amp;quot;&amp;quot;&amp;quot;\n        # Test with invalid session ID\n        mentions = db_manager.get_mentions_by_session(&amp;quot;invalid_session_id&amp;quot;)\n        assert mentions == []\n    \n        # Test with invalid mention data\n        session_id = db_manager.create_search_session(&amp;quot;error_test&amp;quot;)\n    \n        invalid_mention = {\n            &amp;#x27;reddit_id&amp;#x27;: None,  # Invalid - should be string\n            &amp;#x27;title&amp;#x27;: &amp;#x27;Test&amp;#x27;,\n            &amp;#x27;content&amp;#x27;: &amp;#x27;Test content&amp;#x27;\n        }\n    \n        # Should handle gracefully\n&amp;gt;       mention_id = db_manager.add_mention(session_id, invalid_mention)\nE       TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:234: TypeError\n&#34;}], &#34;tests/test_database.py::test_concurrent_database_access&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_concurrent_database_access&#34;, &#34;duration&#34;: &#34;54 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_concurrent_database_access&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;54 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_database.py::test_database_backup_restore&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_database_backup_restore&#34;, &#34;duration&#34;: &#34;13 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_database_backup_restore&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;13 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;db_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDC9BC4D0&amp;gt;\n\n    @pytest.mark.unit\n    def test_database_backup_restore(db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test database backup and restore functionality.&amp;quot;&amp;quot;&amp;quot;\n        # Create test data\n        session_id = db_manager.create_search_session(&amp;quot;backup_test&amp;quot;)\n    \n        test_mention = {\n            &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;backup_test_1&amp;#x27;,\n            &amp;#x27;title&amp;#x27;: &amp;#x27;Backup test post&amp;#x27;,\n            &amp;#x27;content&amp;#x27;: &amp;#x27;This is a backup test.&amp;#x27;,\n            &amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;,\n            &amp;#x27;subreddit&amp;#x27;: &amp;#x27;test&amp;#x27;,\n            &amp;#x27;score&amp;#x27;: 42,\n            &amp;#x27;num_comments&amp;#x27;: 5,\n            &amp;#x27;created_utc&amp;#x27;: datetime.utcnow(),\n            &amp;#x27;sentiment_score&amp;#x27;: 0.5,\n            &amp;#x27;relevance_score&amp;#x27;: 0.8\n        }\n    \n&amp;gt;       db_manager.add_mention(session_id, test_mention)\nE       TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_database.py:290: TypeError\n&#34;}], &#34;tests/test_database.py::test_async_database_operations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::test_async_database_operations&#34;, &#34;duration&#34;: &#34;127 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::test_async_database_operations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;127 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_database.py::TestSearchSession::test_search_session_creation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::TestSearchSession::test_search_session_creation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::TestSearchSession::test_search_session_creation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_database.TestSearchSession object at 0x000001BEA554A450&amp;gt;\n\n    @pytest.mark.unit\n    def test_search_session_creation(self):\n        &amp;quot;&amp;quot;&amp;quot;Test SearchSession model creation.&amp;quot;&amp;quot;&amp;quot;\n        session = SearchSession(\n            search_term=&amp;quot;test&amp;quot;,\n            status=&amp;quot;active&amp;quot;\n        )\n    \n        assert session.search_term == &amp;quot;test&amp;quot;\n        assert session.status == &amp;quot;active&amp;quot;\n&amp;gt;       assert session.created_at is not None\nE       assert None is not None\nE        +  where None = &amp;lt;database.models.SearchSession object at 0x000001BEDC9BD040&amp;gt;.created_at\n\ntests\\test_database.py:344: AssertionError\n&#34;}], &#34;tests/test_database.py::TestSearchSession::test_search_session_to_dict&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::TestSearchSession::test_search_session_to_dict&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::TestSearchSession::test_search_session_to_dict&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_database.TestSearchSession object at 0x000001BEA554A0F0&amp;gt;\n\n    @pytest.mark.unit\n    def test_search_session_to_dict(self):\n        &amp;quot;&amp;quot;&amp;quot;Test SearchSession to_dict method.&amp;quot;&amp;quot;&amp;quot;\n        session = SearchSession(\n            search_term=&amp;quot;test&amp;quot;,\n            status=&amp;quot;completed&amp;quot;\n        )\n    \n&amp;gt;       session_dict = session.to_dict()\nE       AttributeError: &amp;#x27;SearchSession&amp;#x27; object has no attribute &amp;#x27;to_dict&amp;#x27;\n\ntests\\test_database.py:355: AttributeError\n&#34;}], &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_creation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_creation::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::TestRedditMention::test_reddit_mention_creation::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py, line 367\n      @pytest.mark.unit\n      def test_reddit_mention_creation(self, sample_mention):\nE       fixture &amp;#x27;sample_mention&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py:367\n&#34;}], &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_to_dict&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_to_dict::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::TestRedditMention::test_reddit_mention_to_dict::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py, line 377\n      @pytest.mark.unit\n      def test_reddit_mention_to_dict(self, sample_mention):\nE       fixture &amp;#x27;sample_mention&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_database.py:377\n&#34;}], &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_database.py::TestRedditMention::test_reddit_mention_validation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_database.py::TestRedditMention::test_reddit_mention_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_database.TestRedditMention object at 0x000001BEA554AD50&amp;gt;\n\n    @pytest.mark.unit\n    def test_reddit_mention_validation(self):\n        &amp;quot;&amp;quot;&amp;quot;Test RedditMention validation.&amp;quot;&amp;quot;&amp;quot;\n        # Test with minimal required fields\n        minimal_mention = RedditMention(\n            reddit_id=&amp;quot;test123&amp;quot;,\n            title=&amp;quot;Test Title&amp;quot;\n        )\n    \n        assert minimal_mention.reddit_id == &amp;quot;test123&amp;quot;\n        assert minimal_mention.title == &amp;quot;Test Title&amp;quot;\n    \n        # Optional fields should have defaults\n&amp;gt;       assert minimal_mention.score == 0\nE       assert None == 0\nE        +  where None = &amp;lt;database.models.RedditMention object at 0x000001BEDC9A7380&amp;gt;.score\n\ntests\\test_database.py:401: AssertionError\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_scraper_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_scraper_initialization&#34;, &#34;duration&#34;: &#34;54 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_scraper_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;54 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_sanitize_search_term&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_sanitize_search_term&#34;, &#34;duration&#34;: &#34;51 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_sanitize_search_term&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;51 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_generate_cache_key&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_generate_cache_key&#34;, &#34;duration&#34;: &#34;52 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_generate_cache_key&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;52 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_extract_reddit_id&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_extract_reddit_id&#34;, &#34;duration&#34;: &#34;46 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_extract_reddit_id&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;46 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_parse_score&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_parse_score&#34;, &#34;duration&#34;: &#34;44 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_parse_score&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;44 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_parse_comment_count&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_parse_comment_count&#34;, &#34;duration&#34;: &#34;51 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_parse_comment_count&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;51 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_calculate_relevance_score&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_calculate_relevance_score&#34;, &#34;duration&#34;: &#34;44 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_calculate_relevance_score&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;44 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_scraper.TestRedditScraper object at 0x000001BED7C48080&amp;gt;\nscraper = &amp;lt;scraper.reddit_scraper.RedditScraper object at 0x000001BEDC9A7A10&amp;gt;\n\n    @pytest.mark.unit\n    def test_calculate_relevance_score(self, scraper):\n        &amp;quot;&amp;quot;&amp;quot;Test relevance score calculation.&amp;quot;&amp;quot;&amp;quot;\n        # High relevance post\n        high_relevance = {\n            &amp;#x27;title&amp;#x27;: &amp;#x27;OpenAI releases new GPT model&amp;#x27;,\n            &amp;#x27;content&amp;#x27;: &amp;#x27;OpenAI has announced a breakthrough in AI technology&amp;#x27;,\n            &amp;#x27;score&amp;#x27;: 1000,\n            &amp;#x27;num_comments&amp;#x27;: 500\n        }\n    \n&amp;gt;       score = scraper._calculate_relevance_score(high_relevance, &amp;quot;OpenAI&amp;quot;)\nE       TypeError: RedditScraper._calculate_relevance_score() missing 1 required positional argument: &amp;#x27;search_term&amp;#x27;\n\ntests\\test_scraper.py:104: TypeError\n\n------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_calculate_basic_sentiment&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_calculate_basic_sentiment&#34;, &#34;duration&#34;: &#34;248 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_calculate_basic_sentiment&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;248 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_is_relevant&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_is_relevant&#34;, &#34;duration&#34;: &#34;53 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_is_relevant&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;53 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestRedditScraper::test_remove_duplicates&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestRedditScraper::test_remove_duplicates&#34;, &#34;duration&#34;: &#34;53 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestRedditScraper::test_remove_duplicates&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;53 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_success&#34;, &#34;duration&#34;: &#34;71 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;71 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_missing_elements&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_missing_elements&#34;, &#34;duration&#34;: &#34;50 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_extract_post_data_missing_elements&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;50 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_handle_popups&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_handle_popups&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_handle_popups&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_with_cache_hit&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_with_cache_hit&#34;, &#34;duration&#34;: &#34;55 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_with_cache_hit&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;55 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_error_handling&#34;, &#34;duration&#34;: &#34;57 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_scrape_mentions_error_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;57 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n------------------------------ Captured log call -------------------------------\nERROR    scraper.reddit_scraper:reddit_scraper.py:343 Scraping failed for &amp;#x27;OpenAI&amp;#x27;: Playwright error\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingWithMocks::test_circuit_breaker_functionality&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingWithMocks::test_circuit_breaker_functionality&#34;, &#34;duration&#34;: &#34;56 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingWithMocks::test_circuit_breaker_functionality&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;56 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n------------------------------ Captured log call -------------------------------\nWARNING  scraper.reddit_scraper:reddit_scraper.py:244 Circuit breaker opened due to repeated failures\nWARNING  scraper.reddit_scraper:reddit_scraper.py:244 Circuit breaker opened due to repeated failures\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingPerformance::test_rate_limiting&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingPerformance::test_rate_limiting&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingPerformance::test_rate_limiting&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingPerformance::test_concurrent_scraping_limits&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingPerformance::test_concurrent_scraping_limits&#34;, &#34;duration&#34;: &#34;153 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingPerformance::test_concurrent_scraping_limits&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;153 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingIntegration::test_full_scraping_pipeline_mock&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingIntegration::test_full_scraping_pipeline_mock&#34;, &#34;duration&#34;: &#34;00:01:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingIntegration::test_full_scraping_pipeline_mock&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;scraper.reddit_scraper.RedditScraper object at 0x000001BEDE29F470&amp;gt;\nsearch_term = &amp;#x27;OpenAI&amp;#x27;, session_id = 1, max_pages = 1, progress_callback = None\nuse_advanced_patterns = True, quality_threshold = 0.3\n\n    async def scrape_mentions(\n        self,\n        search_term: str,\n        session_id: int,\n        max_pages: int = 5,\n        progress_callback: Optional[Callable] = None,\n        use_advanced_patterns: bool = True,\n        quality_threshold: float = 0.3\n    ) -&amp;gt; List[Dict[str, Any]]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Enhanced scraping with comprehensive error handling and quality filtering.\n        &amp;quot;&amp;quot;&amp;quot;\n        # Input validation and sanitization\n        search_term = self._sanitize_search_term(search_term)\n        if not search_term:\n            raise ValueError(&amp;quot;Invalid search term after sanitization&amp;quot;)\n    \n        # Check circuit breaker\n        if not self._check_circuit_breaker():\n            raise ScrapingError(&amp;quot;Circuit breaker is open, scraping temporarily disabled&amp;quot;)\n    \n        # Initialize metrics\n        metrics = ScrapingMetrics(start_time=datetime.utcnow())\n    \n        # Check cache with enhanced key\n        cache_key = self._generate_cache_key(search_term, max_pages, quality_threshold)\n        if self.cache_manager:\n            cached_mentions = self.cache_manager.get_search_results(cache_key)\n            if cached_mentions:\n                metrics.cache_hits = 1\n                self.logger.info(f&amp;quot;Found {len(cached_mentions)} cached mentions for &amp;#x27;{search_term}&amp;#x27;&amp;quot;)\n                if self.monitor:\n                    self.monitor.emit_cache_hit(search_term, len(cached_mentions))\n                return cached_mentions\n    \n        all_mentions = []\n    \n        try:\n            # Enhanced browser setup with stealth mode\n            async with async_playwright() as p:\n                browser = await self._create_stealth_browser(p)\n    \n                try:\n                    context = await self._create_browser_context(browser)\n                    page = await context.new_page()\n    \n                    # Set up page monitoring\n                    await self._setup_page_monitoring(page)\n    \n                    # Progressive scraping strategy\n                    if use_advanced_patterns:\n                        mentions = await self._progressive_scraping(\n                            page, search_term, session_id, max_pages,\n                            progress_callback, metrics, quality_threshold\n                        )\n                    else:\n                        mentions = await self._basic_scraping(\n                            page, search_term, session_id, max_pages,\n                            progress_callback, metrics\n                        )\n    \n                    all_mentions.extend(mentions)\n    \n                finally:\n                    await browser.close()\n    \n            # Post-processing and quality enhancement\n            if progress_callback:\n                progress_callback(&amp;quot;\ud83d\udd0d Processing and enhancing mentions...&amp;quot;, 0.9)\n    \n&amp;gt;           enhanced_mentions = await self._post_process_mentions(\n                all_mentions, search_term, quality_threshold, metrics\n            )\nE           AttributeError: &amp;#x27;RedditScraper&amp;#x27; object has no attribute &amp;#x27;_post_process_mentions&amp;#x27;\n\nscraper\\reddit_scraper.py:316: AttributeError\n\nThe above exception was the direct cause of the following exception:\n\nself = &amp;lt;tests.test_scraper.TestScrapingIntegration object at 0x000001BED7C49640&amp;gt;\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDE29FF50&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 37, 44, 537284), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.asyncio\n    async def test_full_scraping_pipeline_mock(self, db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test full scraping pipeline with mocked browser.&amp;quot;&amp;quot;&amp;quot;\n        scraper = RedditScraper(db_manager)\n    \n        # Mock the entire browser interaction\n        with patch(&amp;#x27;scraper.reddit_scraper.async_playwright&amp;#x27;) as mock_playwright:\n            # Setup mock browser\n            mock_browser = AsyncMock()\n            mock_context = AsyncMock()\n            mock_page = AsyncMock()\n    \n            mock_playwright.return_value.__aenter__.return_value.chromium.launch.return_value = mock_browser\n            mock_browser.new_context.return_value = mock_context\n            mock_context.new_page.return_value = mock_page\n    \n            # Mock page interactions\n            mock_page.goto = AsyncMock()\n            mock_page.wait_for_selector = AsyncMock()\n            mock_page.query_selector_all.return_value = []  # No posts found\n    \n            # Run scraping\n&amp;gt;           result = await scraper.scrape_mentions(&amp;quot;OpenAI&amp;quot;, 1, max_pages=1)\n\ntests\\test_scraper.py:389: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;scraper.reddit_scraper.RedditScraper object at 0x000001BEDE29F470&amp;gt;\nsearch_term = &amp;#x27;OpenAI&amp;#x27;, session_id = 1, max_pages = 1, progress_callback = None\nuse_advanced_patterns = True, quality_threshold = 0.3\n\n    async def scrape_mentions(\n        self,\n        search_term: str,\n        session_id: int,\n        max_pages: int = 5,\n        progress_callback: Optional[Callable] = None,\n        use_advanced_patterns: bool = True,\n        quality_threshold: float = 0.3\n    ) -&amp;gt; List[Dict[str, Any]]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Enhanced scraping with comprehensive error handling and quality filtering.\n        &amp;quot;&amp;quot;&amp;quot;\n        # Input validation and sanitization\n        search_term = self._sanitize_search_term(search_term)\n        if not search_term:\n            raise ValueError(&amp;quot;Invalid search term after sanitization&amp;quot;)\n    \n        # Check circuit breaker\n        if not self._check_circuit_breaker():\n            raise ScrapingError(&amp;quot;Circuit breaker is open, scraping temporarily disabled&amp;quot;)\n    \n        # Initialize metrics\n        metrics = ScrapingMetrics(start_time=datetime.utcnow())\n    \n        # Check cache with enhanced key\n        cache_key = self._generate_cache_key(search_term, max_pages, quality_threshold)\n        if self.cache_manager:\n            cached_mentions = self.cache_manager.get_search_results(cache_key)\n            if cached_mentions:\n                metrics.cache_hits = 1\n                self.logger.info(f&amp;quot;Found {len(cached_mentions)} cached mentions for &amp;#x27;{search_term}&amp;#x27;&amp;quot;)\n                if self.monitor:\n                    self.monitor.emit_cache_hit(search_term, len(cached_mentions))\n                return cached_mentions\n    \n        all_mentions = []\n    \n        try:\n            # Enhanced browser setup with stealth mode\n            async with async_playwright() as p:\n                browser = await self._create_stealth_browser(p)\n    \n                try:\n                    context = await self._create_browser_context(browser)\n                    page = await context.new_page()\n    \n                    # Set up page monitoring\n                    await self._setup_page_monitoring(page)\n    \n                    # Progressive scraping strategy\n                    if use_advanced_patterns:\n                        mentions = await self._progressive_scraping(\n                            page, search_term, session_id, max_pages,\n                            progress_callback, metrics, quality_threshold\n                        )\n                    else:\n                        mentions = await self._basic_scraping(\n                            page, search_term, session_id, max_pages,\n                            progress_callback, metrics\n                        )\n    \n                    all_mentions.extend(mentions)\n    \n                finally:\n                    await browser.close()\n    \n            # Post-processing and quality enhancement\n            if progress_callback:\n                progress_callback(&amp;quot;\ud83d\udd0d Processing and enhancing mentions...&amp;quot;, 0.9)\n    \n            enhanced_mentions = await self._post_process_mentions(\n                all_mentions, search_term, quality_threshold, metrics\n            )\n    \n            # Cache results with enhanced key\n            if self.cache_manager and enhanced_mentions:\n                self.cache_manager.set_search_results(cache_key, enhanced_mentions)\n    \n            # Record success\n            self._record_success()\n            metrics.end_time = datetime.utcnow()\n            metrics.mentions_found = len(enhanced_mentions)\n    \n            # Log comprehensive metrics\n            self._log_scraping_metrics(metrics, search_term)\n    \n            if progress_callback:\n                progress_callback(f&amp;quot;\u2705 Completed! Found {len(enhanced_mentions)} high-quality mentions&amp;quot;, 1.0)\n    \n            return enhanced_mentions\n    \n        except Exception as e:\n            self._record_failure()\n            metrics.end_time = datetime.utcnow()\n            metrics.errors_encountered += 1\n    \n            error_msg = f&amp;quot;Scraping failed for &amp;#x27;{search_term}&amp;#x27;: {str(e)}&amp;quot;\n            self.logger.error(error_msg)\n    \n            if self.monitor:\n                self.monitor.emit_search_failed(session_id, error_msg)\n    \n            if progress_callback:\n                progress_callback(f&amp;quot;\u274c Error: {error_msg}&amp;quot;, 1.0)\n    \n            # Return partial results if any\n            if all_mentions:\n                self.logger.info(f&amp;quot;Returning {len(all_mentions)} partial results despite error&amp;quot;)\n                return all_mentions\n    \n&amp;gt;           raise ScrapingError(error_msg) from e\nE           scraper.reddit_scraper.ScrapingError: Scraping failed for &amp;#x27;OpenAI&amp;#x27;: &amp;#x27;RedditScraper&amp;#x27; object has no attribute &amp;#x27;_post_process_mentions&amp;#x27;\n\nscraper\\reddit_scraper.py:356: ScrapingError\n\n------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\nERROR    scraper.reddit_scraper:reddit_scraper.py:343 Scraping failed for &amp;#x27;OpenAI&amp;#x27;: &amp;#x27;RedditScraper&amp;#x27; object has no attribute &amp;#x27;_post_process_mentions&amp;#x27;\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingIntegration::test_post_processing_pipeline&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingIntegration::test_post_processing_pipeline&#34;, &#34;duration&#34;: &#34;39 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingIntegration::test_post_processing_pipeline&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;39 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_scraper.TestScrapingIntegration object at 0x000001BED7C48B00&amp;gt;\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDECC42C0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 48, 730724), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.asyncio\n    async def test_post_processing_pipeline(self, db_manager, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test post-processing pipeline.&amp;quot;&amp;quot;&amp;quot;\n        scraper = RedditScraper(db_manager)\n    \n        # Test the post-processing method directly\n&amp;gt;       enhanced_mentions = await scraper._post_process_mentions(\n            sample_mentions_list, &amp;quot;OpenAI&amp;quot;, 0.3, None\n        )\nE       AttributeError: &amp;#x27;RedditScraper&amp;#x27; object has no attribute &amp;#x27;_post_process_mentions&amp;#x27;\n\ntests\\test_scraper.py:403: AttributeError\n\n------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingIntegration::test_error_recovery&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingIntegration::test_error_recovery&#34;, &#34;duration&#34;: &#34;38 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingIntegration::test_error_recovery&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;38 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_scraper.TestScrapingIntegration object at 0x000001BED7C483E0&amp;gt;\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEDEC49A90&amp;gt;\n\n    @pytest.mark.asyncio\n    async def test_error_recovery(self, db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test error recovery mechanisms.&amp;quot;&amp;quot;&amp;quot;\n        scraper = RedditScraper(db_manager)\n    \n        # Test with invalid search term\n&amp;gt;       result = await scraper.scrape_mentions(&amp;quot;&amp;quot;, 1)\n\ntests\\test_scraper.py:422: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;scraper.reddit_scraper.RedditScraper object at 0x000001BEDEC49C10&amp;gt;\nsearch_term = &amp;#x27;&amp;#x27;, session_id = 1, max_pages = 5, progress_callback = None\nuse_advanced_patterns = True, quality_threshold = 0.3\n\n    async def scrape_mentions(\n        self,\n        search_term: str,\n        session_id: int,\n        max_pages: int = 5,\n        progress_callback: Optional[Callable] = None,\n        use_advanced_patterns: bool = True,\n        quality_threshold: float = 0.3\n    ) -&amp;gt; List[Dict[str, Any]]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Enhanced scraping with comprehensive error handling and quality filtering.\n        &amp;quot;&amp;quot;&amp;quot;\n        # Input validation and sanitization\n        search_term = self._sanitize_search_term(search_term)\n        if not search_term:\n&amp;gt;           raise ValueError(&amp;quot;Invalid search term after sanitization&amp;quot;)\nE           ValueError: Invalid search term after sanitization\n\nscraper\\reddit_scraper.py:261: ValueError\n\n------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_proxy_configuration&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_proxy_configuration&#34;, &#34;duration&#34;: &#34;40 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_proxy_configuration&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;40 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_user_agent_rotation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_user_agent_rotation&#34;, &#34;duration&#34;: &#34;39 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_user_agent_rotation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;39 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_search_patterns_configuration&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_search_patterns_configuration&#34;, &#34;duration&#34;: &#34;39 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_search_patterns_configuration&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;39 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_subreddit_categories&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_subreddit_categories&#34;, &#34;duration&#34;: &#34;39 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_subreddit_categories&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;39 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_build_search_patterns&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_build_search_patterns::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_build_search_patterns::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 487\n      @pytest.mark.unit\n      def test_build_search_patterns(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:487\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_filter_by_quality&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_filter_by_quality::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_filter_by_quality::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 498\n      @pytest.mark.unit\n      def test_filter_by_quality(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:498\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_deduplicate_mentions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_deduplicate_mentions::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_deduplicate_mentions::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 513\n      @pytest.mark.unit\n      def test_deduplicate_mentions(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:513\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_validate_mention_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_validate_mention_data::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_validate_mention_data::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 529\n      @pytest.mark.unit\n      def test_validate_mention_data(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:529\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_error_handling::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_error_handling::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 565\n      @pytest.mark.unit\n      def test_error_handling(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:565\n&#34;}], &#34;tests/test_scraper.py::TestScrapingConfiguration::test_rate_limiting_configuration&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_scraper.py::TestScrapingConfiguration::test_rate_limiting_configuration::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_scraper.py::TestScrapingConfiguration::test_rate_limiting_configuration::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py, line 579\n      @pytest.mark.unit\n      def test_rate_limiting_configuration(self, scraper):\nE       fixture &amp;#x27;scraper&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_scraper.py:579\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_analyzer_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_analyzer_initialization&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_analyzer_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_basic_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_basic_metrics&#34;, &#34;duration&#34;: &#34;43 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_basic_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;43 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_analyze_session_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_analyze_session_metrics&#34;, &#34;duration&#34;: &#34;33 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_analyze_session_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;33 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_temporal_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_temporal_metrics&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_temporal_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C6BB30&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF3D4BC0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 15, 38, 49, 105719), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_calculate_temporal_metrics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test temporal metrics calculation.&amp;quot;&amp;quot;&amp;quot;\n        # Add timestamps to mentions\n        now = datetime.utcnow()\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;created_utc&amp;#x27;] = now - timedelta(hours=i)\n    \n&amp;gt;       metrics = metrics_analyzer.calculate_temporal_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;calculate_temporal_metrics&amp;#x27;. Did you mean: &amp;#x27;_calculate_temporal_metrics&amp;#x27;?\n\ntests\\test_analytics.py:112: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_subreddit_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_subreddit_metrics&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_subreddit_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C6BDA0&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF3D6660&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 49, 126720), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_calculate_subreddit_metrics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test subreddit metrics calculation.&amp;quot;&amp;quot;&amp;quot;\n        # Add different subreddits\n        subreddits = [&amp;#x27;technology&amp;#x27;, &amp;#x27;programming&amp;#x27;, &amp;#x27;artificial&amp;#x27;, &amp;#x27;MachineLearning&amp;#x27;]\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;subreddit&amp;#x27;] = subreddits[i % len(subreddits)]\n    \n&amp;gt;       metrics = metrics_analyzer.calculate_subreddit_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;calculate_subreddit_metrics&amp;#x27;. Did you mean: &amp;#x27;_calculate_subreddit_metrics&amp;#x27;?\n\ntests\\test_analytics.py:130: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_sentiment_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_sentiment_metrics&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_sentiment_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C88050&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF3D6FF0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 49, 147719), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_calculate_sentiment_metrics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test sentiment metrics calculation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = metrics_analyzer.calculate_sentiment_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;calculate_sentiment_metrics&amp;#x27;. Did you mean: &amp;#x27;_calculate_sentiment_metrics&amp;#x27;?\n\ntests\\test_analytics.py:142: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_engagement_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_engagement_metrics&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_calculate_engagement_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C882C0&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF419640&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 49, 166719), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_calculate_engagement_metrics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test engagement metrics calculation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = metrics_analyzer.calculate_engagement_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;calculate_engagement_metrics&amp;#x27;. Did you mean: &amp;#x27;_calculate_engagement_metrics&amp;#x27;?\n\ntests\\test_analytics.py:159: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_detect_trending_topics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_detect_trending_topics&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_detect_trending_topics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C88530&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF41AA80&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 49, 186720), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_detect_trending_topics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test trending topic detection.&amp;quot;&amp;quot;&amp;quot;\n        # Add keywords to titles\n        keywords = [&amp;#x27;AI&amp;#x27;, &amp;#x27;machine learning&amp;#x27;, &amp;#x27;neural networks&amp;#x27;, &amp;#x27;deep learning&amp;#x27;]\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;title&amp;#x27;] = f&amp;quot;Post about {keywords[i % len(keywords)]} technology&amp;quot;\n    \n&amp;gt;       trending = metrics_analyzer.detect_trending_topics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;detect_trending_topics&amp;#x27;\n\ntests\\test_analytics.py:180: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_generate_comprehensive_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_generate_comprehensive_metrics&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_generate_comprehensive_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C887A0&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF3D7920&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 49, 211721), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_generate_comprehensive_metrics(self, metrics_analyzer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test comprehensive metrics generation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = metrics_analyzer.generate_comprehensive_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:192: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_empty_mentions_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_empty_mentions_handling&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_empty_mentions_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C88A10&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDF3D5070&amp;gt;\n\n    @pytest.mark.unit\n    def test_empty_mentions_handling(self, metrics_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test handling of empty mentions list.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = metrics_analyzer.generate_comprehensive_metrics([])\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:211: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_malformed_data_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestMetricsAnalyzer::test_malformed_data_handling&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestMetricsAnalyzer::test_malformed_data_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestMetricsAnalyzer object at 0x000001BED7C88C80&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEDE5D7860&amp;gt;\n\n    @pytest.mark.unit\n    def test_malformed_data_handling(self, metrics_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test handling of malformed data.&amp;quot;&amp;quot;&amp;quot;\n        malformed_mentions = [\n            {&amp;#x27;title&amp;#x27;: &amp;#x27;Valid post&amp;#x27;, &amp;#x27;score&amp;#x27;: 10},  # Missing fields\n            {&amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test&amp;#x27;, &amp;#x27;score&amp;#x27;: &amp;#x27;invalid&amp;#x27;},  # Invalid score type\n            {},  # Empty mention\n            None  # None mention\n        ]\n    \n        # Should handle gracefully without crashing\n&amp;gt;       metrics = metrics_analyzer.generate_comprehensive_metrics(malformed_mentions)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:229: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_validator_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_validator_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_validator_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_valid_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_valid_data&#34;, &#34;duration&#34;: &#34;209 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_validate_mention_valid_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;209 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_invalid_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_invalid_data&#34;, &#34;duration&#34;: &#34;8 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_validate_mention_invalid_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;8 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_spam_detection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_validate_mention_spam_detection&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_validate_mention_spam_detection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_validate_dataset&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_validate_dataset&#34;, &#34;duration&#34;: &#34;123 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_validate_dataset&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;123 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_duplicate_detection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_duplicate_detection&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_duplicate_detection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_language_analysis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_language_analysis&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_language_analysis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_content_quality_analysis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_content_quality_analysis&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_content_quality_analysis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestDataValidator::test_quality_metrics_calculation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestDataValidator::test_quality_metrics_calculation&#34;, &#34;duration&#34;: &#34;99 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestDataValidator::test_quality_metrics_calculation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;99 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyzer_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyzer_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyzer_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAdvancedSentimentAnalyzer object at 0x000001BED7C88C20&amp;gt;\nsentiment_analyzer = &amp;lt;analytics.advanced_sentiment.AdvancedSentimentAnalyzer object at 0x000001BEE2533CB0&amp;gt;\n\n    def test_analyzer_initialization(self, sentiment_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test sentiment analyzer initialization.&amp;quot;&amp;quot;&amp;quot;\n        assert sentiment_analyzer is not None\n&amp;gt;       assert hasattr(sentiment_analyzer, &amp;#x27;providers&amp;#x27;)\nE       AssertionError: assert False\nE        +  where False = hasattr(&amp;lt;analytics.advanced_sentiment.AdvancedSentimentAnalyzer object at 0x000001BEE2533CB0&amp;gt;, &amp;#x27;providers&amp;#x27;)\n\ntests\\test_analytics.py:396: AssertionError\n\n------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_is_available&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_is_available&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_is_available&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_positive&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_positive&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_positive&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_negative&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_negative&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_negative&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_empty&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_empty&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_sentiment_empty&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_batch&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_batch&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_analyze_batch&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_textblob_analysis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_textblob_analysis&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_textblob_analysis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAdvancedSentimentAnalyzer object at 0x000001BED7C8A1B0&amp;gt;\nsentiment_analyzer = &amp;lt;analytics.advanced_sentiment.AdvancedSentimentAnalyzer object at 0x000001BEE2567380&amp;gt;\n\n    def test_textblob_analysis(self, sentiment_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test TextBlob sentiment analysis.&amp;quot;&amp;quot;&amp;quot;\n        text = &amp;quot;This is a great product!&amp;quot;\n    \n&amp;gt;       result = sentiment_analyzer._analyze_textblob(text)\nE       AttributeError: &amp;#x27;AdvancedSentimentAnalyzer&amp;#x27; object has no attribute &amp;#x27;_analyze_textblob&amp;#x27;\n\ntests\\test_analytics.py:461: AttributeError\n\n------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_vader_analysis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_vader_analysis&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_vader_analysis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAdvancedSentimentAnalyzer object at 0x000001BED7C8A390&amp;gt;\nsentiment_analyzer = &amp;lt;analytics.advanced_sentiment.AdvancedSentimentAnalyzer object at 0x000001BEE2566720&amp;gt;\n\n    def test_vader_analysis(self, sentiment_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test VADER sentiment analysis.&amp;quot;&amp;quot;&amp;quot;\n        text = &amp;quot;This is a great product!&amp;quot;\n    \n&amp;gt;       if sentiment_analyzer._is_vader_available():\nE       AttributeError: &amp;#x27;AdvancedSentimentAnalyzer&amp;#x27; object has no attribute &amp;#x27;_is_vader_available&amp;#x27;\n\ntests\\test_analytics.py:473: AttributeError\n\n------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_emotion_detection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_emotion_detection&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAdvancedSentimentAnalyzer::test_emotion_detection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAdvancedSentimentAnalyzer object at 0x000001BED7C8A570&amp;gt;\nsentiment_analyzer = &amp;lt;analytics.advanced_sentiment.AdvancedSentimentAnalyzer object at 0x000001BEE25662D0&amp;gt;\n\n    def test_emotion_detection(self, sentiment_analyzer):\n        &amp;quot;&amp;quot;&amp;quot;Test emotion detection.&amp;quot;&amp;quot;&amp;quot;\n        emotional_texts = {\n            &amp;quot;I&amp;#x27;m so happy and excited!&amp;quot;: &amp;quot;joy&amp;quot;,\n            &amp;quot;I&amp;#x27;m really angry about this!&amp;quot;: &amp;quot;anger&amp;quot;,\n            &amp;quot;This makes me so sad.&amp;quot;: &amp;quot;sadness&amp;quot;,\n            &amp;quot;I&amp;#x27;m terrified and scared.&amp;quot;: &amp;quot;fear&amp;quot;\n        }\n    \n        for text, expected_emotion in emotional_texts.items():\n&amp;gt;           emotions = sentiment_analyzer._detect_emotions(text)\nE           AttributeError: &amp;#x27;AdvancedSentimentAnalyzer&amp;#x27; object has no attribute &amp;#x27;_detect_emotions&amp;#x27;\n\ntests\\test_analytics.py:491: AttributeError\n\n------------------------------ Captured log setup ------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n&#34;}], &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_full_analytics_pipeline&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_full_analytics_pipeline&#34;, &#34;duration&#34;: &#34;108 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsIntegration::test_full_analytics_pipeline&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;108 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAnalyticsIntegration object at 0x000001BED7C8A840&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEE2533CB0&amp;gt;\ndata_validator = &amp;lt;analytics.data_validator.DataValidator object at 0x000001BEE2564B90&amp;gt;\nsample_mentions_list = [{&amp;#x27;_quality_level&amp;#x27;: &amp;#x27;good&amp;#x27;, &amp;#x27;_quality_score&amp;#x27;: 0.7187495562774593, &amp;#x27;_validation_issues&amp;#x27;: 2, &amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, ...}...uality_level&amp;#x27;: &amp;#x27;good&amp;#x27;, &amp;#x27;_quality_score&amp;#x27;: 0.7687496244910119, &amp;#x27;_validation_issues&amp;#x27;: 2, &amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, ...}, ...]\n\n    def test_full_analytics_pipeline(self, metrics_analyzer, data_validator, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test full analytics pipeline.&amp;quot;&amp;quot;&amp;quot;\n        # Step 1: Validate data\n        validated_mentions, quality_metrics = data_validator.validate_dataset(sample_mentions_list)\n    \n        # Step 2: Generate metrics\n&amp;gt;       analytics_metrics = metrics_analyzer.generate_comprehensive_metrics(validated_mentions)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:508: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_with_empty_data&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_with_empty_data&#34;, &#34;duration&#34;: &#34;7 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_with_empty_data&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;7 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAnalyticsIntegration object at 0x000001BED7C8AAB0&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEE2564530&amp;gt;\ndata_validator = &amp;lt;analytics.data_validator.DataValidator object at 0x000001BEE02CF110&amp;gt;\n\n    def test_analytics_with_empty_data(self, metrics_analyzer, data_validator):\n        &amp;quot;&amp;quot;&amp;quot;Test analytics pipeline with empty data.&amp;quot;&amp;quot;&amp;quot;\n        empty_mentions = []\n    \n        # Should handle empty data gracefully\n        validated_mentions, quality_metrics = data_validator.validate_dataset(empty_mentions)\n&amp;gt;       analytics_metrics = metrics_analyzer.generate_comprehensive_metrics(validated_mentions)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:525: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_performance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_performance&#34;, &#34;duration&#34;: &#34;00:00:09&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsIntegration::test_analytics_performance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:09&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAnalyticsIntegration object at 0x000001BED7C8AD20&amp;gt;\nmetrics_analyzer = &amp;lt;analytics.metrics_analyzer.MetricsAnalyzer object at 0x000001BEE02CD2E0&amp;gt;\ndata_validator = &amp;lt;analytics.data_validator.DataValidator object at 0x000001BEE02CC1D0&amp;gt;\nperformance_monitor = &amp;lt;tests.conftest.performance_monitor.&amp;lt;locals&amp;gt;.PerformanceMonitor object at 0x000001BEE0B111C0&amp;gt;\n\n    def test_analytics_performance(self, metrics_analyzer, data_validator, performance_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test analytics performance with large dataset.&amp;quot;&amp;quot;&amp;quot;\n        # Create large dataset\n        large_dataset = []\n        base_mention = {\n            &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test&amp;#x27;,\n            &amp;#x27;title&amp;#x27;: &amp;#x27;Test post about technology&amp;#x27;,\n            &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing various technology topics.&amp;#x27;,\n            &amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;,\n            &amp;#x27;subreddit&amp;#x27;: &amp;#x27;technology&amp;#x27;,\n            &amp;#x27;score&amp;#x27;: 42,\n            &amp;#x27;num_comments&amp;#x27;: 15,\n            &amp;#x27;created_utc&amp;#x27;: datetime.utcnow(),\n            &amp;#x27;sentiment_score&amp;#x27;: 0.5,\n            &amp;#x27;relevance_score&amp;#x27;: 0.8\n        }\n    \n        for i in range(1000):\n            mention = base_mention.copy()\n            mention[&amp;#x27;reddit_id&amp;#x27;] = f&amp;#x27;test_{i}&amp;#x27;\n            mention[&amp;#x27;title&amp;#x27;] = f&amp;#x27;Test post {i} about technology&amp;#x27;\n            large_dataset.append(mention)\n    \n        performance_monitor.start()\n    \n        # Run analytics pipeline\n        validated_mentions, quality_metrics = data_validator.validate_dataset(large_dataset)\n&amp;gt;       analytics_metrics = metrics_analyzer.generate_comprehensive_metrics(validated_mentions)\nE       AttributeError: &amp;#x27;MetricsAnalyzer&amp;#x27; object has no attribute &amp;#x27;generate_comprehensive_metrics&amp;#x27;\n\ntests\\test_analytics.py:558: AttributeError\n&#34;}], &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_metrics_with_extreme_values&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_metrics_with_extreme_values&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsEdgeCases::test_metrics_with_extreme_values&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAnalyticsEdgeCases object at 0x000001BED7C8AFC0&amp;gt;\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEE0203BF0&amp;gt;\n\n    def test_metrics_with_extreme_values(self, db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test metrics calculation with extreme values.&amp;quot;&amp;quot;&amp;quot;\n        metrics_analyzer = MetricsAnalyzer(db_manager)\n    \n        extreme_mentions = [\n            {\n                &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;extreme1&amp;#x27;,\n                &amp;#x27;title&amp;#x27;: &amp;#x27;Post with extreme score&amp;#x27;,\n                &amp;#x27;score&amp;#x27;: 999999,  # Very high score\n                &amp;#x27;num_comments&amp;#x27;: 50000,  # Very high comments\n                &amp;#x27;sentiment_score&amp;#x27;: 1.0,  # Maximum sentiment\n                &amp;#x27;created_utc&amp;#x27;: datetime.utcnow(),\n                &amp;#x27;author&amp;#x27;: &amp;#x27;user1&amp;#x27;,\n                &amp;#x27;subreddit&amp;#x27;: &amp;#x27;test&amp;#x27;\n            },\n            {\n                &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;extreme2&amp;#x27;,\n                &amp;#x27;title&amp;#x27;: &amp;#x27;Post with negative score&amp;#x27;,\n                &amp;#x27;score&amp;#x27;: -1000,  # Negative score\n                &amp;#x27;num_comments&amp;#x27;: 0,  # No comments\n                &amp;#x27;sentiment_score&amp;#x27;: -1.0,  # Minimum sentiment\n                &amp;#x27;created_utc&amp;#x27;: datetime.utcnow(),\n                &amp;#x27;author&amp;#x27;: &amp;#x27;user2&amp;#x27;,\n                &amp;#x27;subreddit&amp;#x27;: &amp;#x27;test&amp;#x27;\n            }\n        ]\n    \n        # Store in database\n        session_id = db_manager.create_search_session(&amp;quot;extreme_values_test&amp;quot;)\n        for mention in extreme_mentions:\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_analytics.py:603: TypeError\n&#34;}], &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_validation_with_unicode_content&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_validation_with_unicode_content&#34;, &#34;duration&#34;: &#34;28 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsEdgeCases::test_validation_with_unicode_content&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;28 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_analytics_with_missing_timestamps&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_analytics.py::TestAnalyticsEdgeCases::test_analytics_with_missing_timestamps&#34;, &#34;duration&#34;: &#34;11 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_analytics.py::TestAnalyticsEdgeCases::test_analytics_with_missing_timestamps&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;11 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_analytics.TestAnalyticsEdgeCases object at 0x000001BED7C8B3E0&amp;gt;\ndb_manager = &amp;lt;database.models.DatabaseManager object at 0x000001BEE0203740&amp;gt;\n\n    def test_analytics_with_missing_timestamps(self, db_manager):\n        &amp;quot;&amp;quot;&amp;quot;Test analytics with missing or invalid timestamps.&amp;quot;&amp;quot;&amp;quot;\n        metrics_analyzer = MetricsAnalyzer(db_manager)\n    \n        mentions_no_timestamps = [\n            {\n                &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;no_time1&amp;#x27;,\n                &amp;#x27;title&amp;#x27;: &amp;#x27;Post without timestamp&amp;#x27;,\n                &amp;#x27;score&amp;#x27;: 10,\n                &amp;#x27;author&amp;#x27;: &amp;#x27;user1&amp;#x27;,\n                &amp;#x27;subreddit&amp;#x27;: &amp;#x27;test&amp;#x27;\n                # Missing created_utc\n            },\n            {\n                &amp;#x27;reddit_id&amp;#x27;: &amp;#x27;bad_time1&amp;#x27;,\n                &amp;#x27;title&amp;#x27;: &amp;#x27;Post with bad timestamp&amp;#x27;,\n                &amp;#x27;score&amp;#x27;: 15,\n                &amp;#x27;created_utc&amp;#x27;: datetime.utcnow(),  # Valid timestamp\n                &amp;#x27;author&amp;#x27;: &amp;#x27;user2&amp;#x27;,\n                &amp;#x27;subreddit&amp;#x27;: &amp;#x27;test&amp;#x27;\n            }\n        ]\n    \n        # Store in database (database will handle missing timestamps)\n        session_id = db_manager.create_search_session(&amp;quot;missing_timestamps_test&amp;quot;)\n        for mention in mentions_no_timestamps:\n            # Add default timestamp if missing\n            if &amp;#x27;created_utc&amp;#x27; not in mention:\n                mention[&amp;#x27;created_utc&amp;#x27;] = datetime.utcnow()\n&amp;gt;           db_manager.add_mention(session_id, mention)\nE           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given\n\ntests\\test_analytics.py:660: TypeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_visualizer_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_visualizer_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_visualizer_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDBF40500&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEDF3D4770&amp;gt;\n\n    @pytest.mark.unit\n    def test_visualizer_initialization(self, visualizer):\n        &amp;quot;&amp;quot;&amp;quot;Test visualizer initialization.&amp;quot;&amp;quot;&amp;quot;\n        assert visualizer is not None\n        assert hasattr(visualizer, &amp;#x27;color_scheme&amp;#x27;)\n&amp;gt;       assert hasattr(visualizer, &amp;#x27;reddit_colors&amp;#x27;)\nE       AssertionError: assert False\nE        +  where False = hasattr(&amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEDF3D4770&amp;gt;, &amp;#x27;reddit_colors&amp;#x27;)\n\ntests\\test_ui.py:24: AssertionError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_mentions_timeline&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_mentions_timeline&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_mentions_timeline&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75D8E0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEDF3D5640&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 15, 38, 58, 656887), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_mentions_timeline(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test mentions timeline creation.&amp;quot;&amp;quot;&amp;quot;\n        # Add timestamps to mentions\n        now = datetime.utcnow()\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;created_utc&amp;#x27;] = now - timedelta(hours=i)\n    \n&amp;gt;       fig = visualizer.create_mentions_timeline(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_mentions_timeline&amp;#x27;\n\ntests\\test_ui.py:34: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_sentiment_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_sentiment_distribution&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_sentiment_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75DBE0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B09DC0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 669887), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_sentiment_distribution(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test sentiment distribution chart.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       fig = visualizer.create_sentiment_distribution(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_sentiment_distribution&amp;#x27;\n\ntests\\test_ui.py:44: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_subreddit_breakdown&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_subreddit_breakdown&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_subreddit_breakdown&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75DDC0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B0BDA0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 685890), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_subreddit_breakdown(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test subreddit breakdown chart.&amp;quot;&amp;quot;&amp;quot;\n        # Add subreddits to mentions\n        subreddits = [&amp;#x27;technology&amp;#x27;, &amp;#x27;programming&amp;#x27;, &amp;#x27;artificial&amp;#x27;, &amp;#x27;MachineLearning&amp;#x27;]\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;subreddit&amp;#x27;] = subreddits[i % len(subreddits)]\n    \n&amp;gt;       fig = visualizer.create_subreddit_breakdown(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_subreddit_breakdown&amp;#x27;. Did you mean: &amp;#x27;create_subreddit_analysis&amp;#x27;?\n\ntests\\test_ui.py:58: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_engagement_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_engagement_metrics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_engagement_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75DFA0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B04E90&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 700890), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_engagement_metrics(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test engagement metrics visualization.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       fig = visualizer.create_engagement_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_engagement_metrics&amp;#x27;. Did you mean: &amp;#x27;create_engagement_analysis&amp;#x27;?\n\ntests\\test_ui.py:67: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_trending_topics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_trending_topics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_trending_topics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75E180&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B065D0&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 712890), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_trending_topics(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test trending topics visualization.&amp;quot;&amp;quot;&amp;quot;\n        # Add keywords to titles\n        keywords = [&amp;#x27;AI&amp;#x27;, &amp;#x27;machine learning&amp;#x27;, &amp;#x27;neural networks&amp;#x27;, &amp;#x27;deep learning&amp;#x27;]\n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;title&amp;#x27;] = f&amp;quot;Post about {keywords[i % len(keywords)]} technology&amp;quot;\n    \n&amp;gt;       fig = visualizer.create_trending_topics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_trending_topics&amp;#x27;\n\ntests\\test_ui.py:81: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_quality_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_quality_metrics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_quality_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75E360&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B04A10&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 725889), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_quality_metrics(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test quality metrics visualization.&amp;quot;&amp;quot;&amp;quot;\n        # Add quality scores\n        for mention in sample_mentions_list:\n            mention[&amp;#x27;relevance_score&amp;#x27;] = 0.8\n            mention[&amp;#x27;quality_score&amp;#x27;] = 0.7\n    \n&amp;gt;       fig = visualizer.create_quality_metrics(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_quality_metrics&amp;#x27;\n\ntests\\test_ui.py:95: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_comprehensive_dashboard&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_create_comprehensive_dashboard&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_create_comprehensive_dashboard&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75E540&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0AFEF30&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 15, 38, 58, 739891), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_create_comprehensive_dashboard(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test comprehensive dashboard creation.&amp;quot;&amp;quot;&amp;quot;\n        # Add required fields\n        now = datetime.utcnow()\n        subreddits = [&amp;#x27;technology&amp;#x27;, &amp;#x27;programming&amp;#x27;, &amp;#x27;artificial&amp;#x27;]\n    \n        for i, mention in enumerate(sample_mentions_list):\n            mention[&amp;#x27;created_utc&amp;#x27;] = now - timedelta(hours=i)\n            mention[&amp;#x27;subreddit&amp;#x27;] = subreddits[i % len(subreddits)]\n            mention[&amp;#x27;relevance_score&amp;#x27;] = 0.8\n            mention[&amp;#x27;quality_score&amp;#x27;] = 0.7\n    \n&amp;gt;       dashboard = visualizer.create_comprehensive_dashboard(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_comprehensive_dashboard&amp;#x27;\n\ntests\\test_ui.py:114: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_empty_data_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_empty_data_handling&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_empty_data_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75E720&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0B05970&amp;gt;\n\n    @pytest.mark.unit\n    def test_empty_data_handling(self, visualizer):\n        &amp;quot;&amp;quot;&amp;quot;Test handling of empty data.&amp;quot;&amp;quot;&amp;quot;\n        empty_mentions = []\n    \n        # Should handle empty data gracefully\n&amp;gt;       fig = visualizer.create_mentions_timeline(empty_mentions)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_mentions_timeline&amp;#x27;\n\ntests\\test_ui.py:132: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_malformed_data_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_malformed_data_handling&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_malformed_data_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75E900&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEDEC55610&amp;gt;\n\n    @pytest.mark.unit\n    def test_malformed_data_handling(self, visualizer):\n        &amp;quot;&amp;quot;&amp;quot;Test handling of malformed data.&amp;quot;&amp;quot;&amp;quot;\n        malformed_mentions = [\n            {&amp;#x27;title&amp;#x27;: &amp;#x27;Valid post&amp;#x27;},  # Missing fields\n            {&amp;#x27;score&amp;#x27;: &amp;#x27;invalid&amp;#x27;},  # Invalid data types\n            {},  # Empty mention\n            None  # None mention\n        ]\n    \n        # Should handle malformed data gracefully\n&amp;gt;       fig = visualizer.create_sentiment_distribution(malformed_mentions)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_sentiment_distribution&amp;#x27;\n\ntests\\test_ui.py:153: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_color_scheme_consistency&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_color_scheme_consistency&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_color_scheme_consistency&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75EAE0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE029A480&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 963065), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_color_scheme_consistency(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test color scheme consistency across charts.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       dashboard = visualizer.create_comprehensive_dashboard(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_comprehensive_dashboard&amp;#x27;\n\ntests\\test_ui.py:159: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_chart_interactivity&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_chart_interactivity&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_chart_interactivity&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75ECC0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0470560&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 976065), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_chart_interactivity(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test chart interactivity features.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       fig = visualizer.create_mentions_timeline(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_mentions_timeline&amp;#x27;\n\ntests\\test_ui.py:170: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestMetricsVisualizer::test_responsive_design&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestMetricsVisualizer::test_responsive_design&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestMetricsVisualizer::test_responsive_design&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestMetricsVisualizer object at 0x000001BEDC75EEA0&amp;gt;\nvisualizer = &amp;lt;ui.visualization.MetricsVisualizer object at 0x000001BEE0A3ED80&amp;gt;\nsample_mentions_list = [{&amp;#x27;author&amp;#x27;: &amp;#x27;test_user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;This is a test post discussing OpenAI technology and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;:...ogy and its impact.&amp;#x27;, &amp;#x27;created_utc&amp;#x27;: datetime.datetime(2025, 5, 28, 20, 38, 58, 990061), &amp;#x27;num_comments&amp;#x27;: 15, ...}, ...]\n\n    @pytest.mark.unit\n    def test_responsive_design(self, visualizer, sample_mentions_list):\n        &amp;quot;&amp;quot;&amp;quot;Test responsive design features.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       fig = visualizer.create_subreddit_breakdown(sample_mentions_list)\nE       AttributeError: &amp;#x27;MetricsVisualizer&amp;#x27; object has no attribute &amp;#x27;create_subreddit_breakdown&amp;#x27;. Did you mean: &amp;#x27;create_subreddit_analysis&amp;#x27;?\n\ntests\\test_ui.py:179: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_monitor_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_monitor_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_monitor_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F0E0&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE2555820&amp;gt;\n\n    @pytest.mark.unit\n    def test_monitor_initialization(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test monitor initialization.&amp;quot;&amp;quot;&amp;quot;\n        assert realtime_monitor is not None\n&amp;gt;       assert hasattr(realtime_monitor, &amp;#x27;system_monitor&amp;#x27;)\nE       AssertionError: assert False\nE        +  where False = hasattr(&amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE2555820&amp;gt;, &amp;#x27;system_monitor&amp;#x27;)\n\ntests\\test_ui.py:198: AssertionError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_system_status&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_system_status&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_get_system_status&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F2C0&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE2554290&amp;gt;\n\n    @pytest.mark.unit\n    def test_get_system_status(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test system status retrieval.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       status = realtime_monitor.get_system_status()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;get_system_status&amp;#x27;. Did you mean: &amp;#x27;emit_system_status&amp;#x27;?\n\ntests\\test_ui.py:204: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_scraping_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_scraping_metrics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_get_scraping_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F4A0&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE25598B0&amp;gt;\n\n    def test_get_scraping_metrics(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test scraping metrics retrieval.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = realtime_monitor.get_scraping_metrics()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;get_scraping_metrics&amp;#x27;\n\ntests\\test_ui.py:219: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_database_metrics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_get_database_metrics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_get_database_metrics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F680&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE254FA40&amp;gt;\n\n    def test_get_database_metrics(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test database metrics retrieval.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       metrics = realtime_monitor.get_database_metrics()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;get_database_metrics&amp;#x27;\n\ntests\\test_ui.py:230: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_create_system_dashboard&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_create_system_dashboard&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_create_system_dashboard&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F860&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE25469F0&amp;gt;\n\n    def test_create_system_dashboard(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test system dashboard creation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       dashboard = realtime_monitor.create_system_dashboard()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;create_system_dashboard&amp;#x27;\n\ntests\\test_ui.py:240: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_create_performance_dashboard&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_create_performance_dashboard&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_create_performance_dashboard&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F770&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE253EB40&amp;gt;\n\n    def test_create_performance_dashboard(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test performance dashboard creation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       dashboard = realtime_monitor.create_performance_dashboard()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;create_performance_dashboard&amp;#x27;\n\ntests\\test_ui.py:253: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_start_monitoring&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_start_monitoring&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_start_monitoring&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75F080&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE25379E0&amp;gt;\n\n    @pytest.mark.asyncio\n    async def test_start_monitoring(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test monitoring start functionality.&amp;quot;&amp;quot;&amp;quot;\n        # Mock the monitoring loop to avoid infinite loop\n&amp;gt;       with patch.object(realtime_monitor, &amp;#x27;_monitoring_loop&amp;#x27;) as mock_loop:\n\ntests\\test_ui.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE2535910&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE25379E0&amp;gt; does not have the attribute &amp;#x27;_monitoring_loop&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_stop_monitoring&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_stop_monitoring&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_stop_monitoring&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75E930&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE253DE20&amp;gt;\n\n    def test_stop_monitoring(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test monitoring stop functionality.&amp;quot;&amp;quot;&amp;quot;\n        # Start monitoring first\n        realtime_monitor.is_monitoring = True\n    \n&amp;gt;       realtime_monitor.stop_monitoring()\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;stop_monitoring&amp;#x27;. Did you mean: &amp;#x27;is_monitoring&amp;#x27;?\n\ntests\\test_ui.py:280: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_alert_system&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_alert_system&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_alert_system&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75E450&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE254F860&amp;gt;\n\n    def test_alert_system(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test alert system functionality.&amp;quot;&amp;quot;&amp;quot;\n        # Test high CPU alert\n        high_cpu_status = {\n            &amp;#x27;cpu_usage&amp;#x27;: 95.0,\n            &amp;#x27;memory_usage&amp;#x27;: 50.0,\n            &amp;#x27;disk_usage&amp;#x27;: 30.0,\n            &amp;#x27;timestamp&amp;#x27;: datetime.utcnow()\n        }\n    \n&amp;gt;       alerts = realtime_monitor._check_alerts(high_cpu_status)\nE       AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;_check_alerts&amp;#x27;\n\ntests\\test_ui.py:294: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestRealtimeMonitor::test_metrics_history&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestRealtimeMonitor::test_metrics_history&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestRealtimeMonitor::test_metrics_history&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestRealtimeMonitor object at 0x000001BEDC75DD30&amp;gt;\nrealtime_monitor = &amp;lt;ui.realtime_monitor.RealTimeMonitor object at 0x000001BEE255A9F0&amp;gt;\n\n    def test_metrics_history(self, realtime_monitor):\n        &amp;quot;&amp;quot;&amp;quot;Test metrics history tracking.&amp;quot;&amp;quot;&amp;quot;\n        # Add some metrics to history\n        for i in range(5):\n            status = {\n                &amp;#x27;cpu_usage&amp;#x27;: 50.0 + i,\n                &amp;#x27;memory_usage&amp;#x27;: 60.0 + i,\n                &amp;#x27;timestamp&amp;#x27;: datetime.utcnow() - timedelta(minutes=i)\n            }\n&amp;gt;           realtime_monitor._add_to_history(status)\nE           AttributeError: &amp;#x27;RealTimeMonitor&amp;#x27; object has no attribute &amp;#x27;_add_to_history&amp;#x27;\n\ntests\\test_ui.py:310: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_interface_creation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_interface_creation&#34;, &#34;duration&#34;: &#34;130 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_interface_creation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;130 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC75FA40&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919352661312&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919352656992&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919352655744&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919352653824&amp;#x27;&amp;gt;, ...}\n\n    def test_interface_creation(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test Gradio interface creation.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       with patch(&amp;#x27;app.create_gradio_interface&amp;#x27;) as mock_create:\n\ntests\\test_ui.py:338: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE2557050&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;create_gradio_interface&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n\n------------------------------ Captured log call -------------------------------\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\nWARNING  analytics.advanced_sentiment:advanced_sentiment.py:29 Transformers not available, falling back to TextBlob only\n\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_search_functionality&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_search_functionality&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_search_functionality&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC75FC20&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291516224&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291516320&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291516416&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291516128&amp;#x27;&amp;gt;, ...}\n\n    def test_search_functionality(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test search functionality in UI.&amp;quot;&amp;quot;&amp;quot;\n        # Mock scraper response\n        mock_mentions = [\n            {&amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test1&amp;#x27;, &amp;#x27;title&amp;#x27;: &amp;#x27;Test post 1&amp;#x27;, &amp;#x27;score&amp;#x27;: 10},\n            {&amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test2&amp;#x27;, &amp;#x27;title&amp;#x27;: &amp;#x27;Test post 2&amp;#x27;, &amp;#x27;score&amp;#x27;: 20}\n        ]\n    \n        mock_app_components[&amp;#x27;scraper&amp;#x27;].scrape_mentions = AsyncMock(return_value=mock_mentions)\n        mock_app_components[&amp;#x27;metrics_analyzer&amp;#x27;].generate_comprehensive_metrics.return_value = {\n            &amp;#x27;basic&amp;#x27;: {&amp;#x27;total_mentions&amp;#x27;: 2}\n        }\n    \n        # Test search function\n&amp;gt;       with patch(&amp;#x27;app.search_mentions&amp;#x27;) as mock_search:\n\ntests\\test_ui.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEDEB074A0&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;search_mentions&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_export_functionality&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_export_functionality&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_export_functionality&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC75FE00&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291520400&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291509744&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291515840&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291514448&amp;#x27;&amp;gt;, ...}\n\n    def test_export_functionality(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test data export functionality.&amp;quot;&amp;quot;&amp;quot;\n        mock_mentions = [\n            {&amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test1&amp;#x27;, &amp;#x27;title&amp;#x27;: &amp;#x27;Test post 1&amp;#x27;, &amp;#x27;score&amp;#x27;: 10},\n            {&amp;#x27;reddit_id&amp;#x27;: &amp;#x27;test2&amp;#x27;, &amp;#x27;title&amp;#x27;: &amp;#x27;Test post 2&amp;#x27;, &amp;#x27;score&amp;#x27;: 20}\n        ]\n    \n&amp;gt;       with patch(&amp;#x27;app.export_data&amp;#x27;) as mock_export:\n\ntests\\test_ui.py:375: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEDEAE1010&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;export_data&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_real_time_updates&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_real_time_updates&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_real_time_updates&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC788050&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377769872&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377770064&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377770352&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377770208&amp;#x27;&amp;gt;, ...}\n\n    def test_real_time_updates(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test real-time updates functionality.&amp;quot;&amp;quot;&amp;quot;\n        mock_status = {\n            &amp;#x27;cpu_usage&amp;#x27;: 45.0,\n            &amp;#x27;memory_usage&amp;#x27;: 60.0,\n            &amp;#x27;active_sessions&amp;#x27;: 3\n        }\n    \n        mock_app_components[&amp;#x27;realtime_monitor&amp;#x27;].get_system_status.return_value = mock_status\n    \n&amp;gt;       with patch(&amp;#x27;app.update_realtime_metrics&amp;#x27;) as mock_update:\n\ntests\\test_ui.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE3D4BCE0&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;update_realtime_metrics&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_error_handling_in_ui&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_error_handling_in_ui&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_error_handling_in_ui&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC788200&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377774000&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919291367856&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377773952&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377772320&amp;#x27;&amp;gt;, ...}\n\n    def test_error_handling_in_ui(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test error handling in UI components.&amp;quot;&amp;quot;&amp;quot;\n        # Mock scraper to raise an error\n        mock_app_components[&amp;#x27;scraper&amp;#x27;].scrape_mentions = AsyncMock(\n            side_effect=Exception(&amp;quot;Scraping error&amp;quot;)\n        )\n    \n&amp;gt;       with patch(&amp;#x27;app.search_mentions&amp;#x27;) as mock_search:\n\ntests\\test_ui.py:407: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE3D4A630&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;search_mentions&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_input_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_input_validation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_input_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC7883E0&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377781680&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377781920&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377781776&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919377782112&amp;#x27;&amp;gt;, ...}\n\n    def test_input_validation(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test input validation in UI.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       with patch(&amp;#x27;app.validate_search_input&amp;#x27;) as mock_validate:\n\ntests\\test_ui.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE3D4BB30&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;validate_search_input&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestGradioInterface::test_progress_tracking&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestGradioInterface::test_progress_tracking&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestGradioInterface::test_progress_tracking&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_ui.TestGradioInterface object at 0x000001BEDC7885C0&amp;gt;\nmock_app_components = {&amp;#x27;db_manager&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919378039792&amp;#x27;&amp;gt;, &amp;#x27;metrics_analyzer&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919300751088&amp;#x27;&amp;gt;, &amp;#x27;realtime_monitor&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919378041424&amp;#x27;&amp;gt;, &amp;#x27;scraper&amp;#x27;: &amp;lt;Mock id=&amp;#x27;1919378036576&amp;#x27;&amp;gt;, ...}\n\n    def test_progress_tracking(self, mock_app_components):\n        &amp;quot;&amp;quot;&amp;quot;Test progress tracking in UI.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       with patch(&amp;#x27;app.track_progress&amp;#x27;) as mock_progress:\n\ntests\\test_ui.py:432: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1455: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = &amp;lt;unittest.mock._patch object at 0x000001BEE3D88410&amp;gt;\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n&amp;gt;           raise AttributeError(\n                &amp;quot;%s does not have the attribute %r&amp;quot; % (target, name)\n            )\nE           AttributeError: &amp;lt;module &amp;#x27;app&amp;#x27; from &amp;#x27;C:\\\\Users\\\\Devansh\\\\Downloads\\\\intern_application_round1\\\\app.py&amp;#x27;&amp;gt; does not have the attribute &amp;#x27;track_progress&amp;#x27;\n\nC:\\Program Files\\Python312\\Lib\\unittest\\mock.py:1428: AttributeError\n&#34;}], &#34;tests/test_ui.py::TestUIIntegration::test_full_ui_workflow&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestUIIntegration::test_full_ui_workflow::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestUIIntegration::test_full_ui_workflow::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py, line 450\n      def test_full_ui_workflow(self, mock_app_components, sample_mentions_list):\nE       fixture &amp;#x27;mock_app_components&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py:450\n&#34;}], &#34;tests/test_ui.py::TestUIIntegration::test_ui_performance_with_large_dataset&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestUIIntegration::test_ui_performance_with_large_dataset::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestUIIntegration::test_ui_performance_with_large_dataset::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py, line 481\n      def test_ui_performance_with_large_dataset(self, mock_app_components, performance_monitor):\nE       fixture &amp;#x27;mock_app_components&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py:481\n&#34;}], &#34;tests/test_ui.py::TestUIIntegration::test_concurrent_ui_operations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestUIIntegration::test_concurrent_ui_operations::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestUIIntegration::test_concurrent_ui_operations::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py, line 517\n      def test_concurrent_ui_operations(self, mock_app_components):\nE       fixture &amp;#x27;mock_app_components&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py:517\n&#34;}], &#34;tests/test_ui.py::TestUIIntegration::test_ui_state_management&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestUIIntegration::test_ui_state_management::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestUIIntegration::test_ui_state_management::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py, line 546\n      def test_ui_state_management(self, mock_app_components):\nE       fixture &amp;#x27;mock_app_components&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py:546\n&#34;}], &#34;tests/test_ui.py::TestUIIntegration::test_ui_accessibility&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;tests/test_ui.py::TestUIIntegration::test_ui_accessibility::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_ui.py::TestUIIntegration::test_ui_accessibility::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;file C:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py, line 563\n      def test_ui_accessibility(self, mock_app_components):\nE       fixture &amp;#x27;mock_app_components&amp;#x27; not found\n&amp;gt;       available fixtures: anyio_backend, anyio_backend_name, anyio_backend_options, async_test_client, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, cov, data_validator, db_manager, doctest_namespace, event_loop, extra, extras, include_metadata_in_junit_xml, metadata, metrics_analyzer, mock_browser_context, mock_playwright_page, mock_redis, mock_requests, mock_textblob, monkeypatch, no_cover, performance_monitor, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_mention_data, sample_mentions_list, temp_database, test_config, test_data_generator, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, visualizer, worker_id\n&amp;gt;       use &amp;#x27;pytest --fixtures [testpath]&amp;#x27; for help on them.\n\nC:\\Users\\Devansh\\Downloads\\intern_application_round1\\tests\\test_ui.py:563\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;test_report_20250529_020718.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>