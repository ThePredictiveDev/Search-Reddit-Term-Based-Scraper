<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="12" skipped="0" tests="12" time="56.223" timestamp="2025-05-29T02:12:51.121193+05:30" hostname="DESKTOP-P3MSMOS"><testcase classname="tests.test_performance.TestDatabasePerformance" name="test_bulk_insert_performance" time="0.026"><failure message="TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given">self = &lt;tests.test_performance.TestDatabasePerformance object at 0x0000024289F2F3B0&gt;
db_manager = &lt;database.models.DatabaseManager object at 0x000002428DB1D7F0&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428C6004A0&gt;

    @pytest.mark.performance
    def test_bulk_insert_performance(self, db_manager, performance_monitor):
        """Test bulk insert performance."""
        # Create large dataset
        large_dataset = []
        base_mention = {
            'reddit_id': 'perf_test',
            'title': 'Performance test post',
            'content': 'This is a performance test post with some content.',
            'author': 'test_user',
            'subreddit': 'test',
            'score': 42,
            'num_comments': 15,
            'created_utc': datetime.utcnow(),
            'sentiment_score': 0.5,
            'relevance_score': 0.8
        }
    
        # Create 1000 mentions for performance testing
        for i in range(1000):
            mention = base_mention.copy()
            mention['reddit_id'] = f'perf_test_{i}'
            mention['title'] = f'Performance test post {i}'
            large_dataset.append(mention)
    
        session_id = db_manager.create_search_session("bulk_insert_test")
    
        performance_monitor.start()
    
        # Insert all mentions
        for mention in large_dataset:
&gt;           db_manager.add_mention(session_id, mention)
E           TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given

tests\test_performance.py:55: TypeError</failure></testcase><testcase classname="tests.test_performance.TestDatabasePerformance" name="test_query_performance" time="0.010"><failure message="TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given">self = &lt;tests.test_performance.TestDatabasePerformance object at 0x000002428DB1C7D0&gt;
db_manager = &lt;database.models.DatabaseManager object at 0x000002428DC2DCD0&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DC2C380&gt;

    @pytest.mark.performance
    def test_query_performance(self, db_manager, performance_monitor):
        """Test query performance with large dataset."""
        # Create test data
        session_ids = []
        mentions_per_session = 100
    
        for i in range(10):
            session_id = db_manager.create_search_session(f"query_test_{i}")
            session_ids.append(session_id)
    
            for j in range(mentions_per_session):
                mention = {
                    'reddit_id': f'query_test_{i}_{j}',
                    'title': f'Query test post {i}_{j}',
                    'content': f'Content for query test {i}_{j}',
                    'author': f'user_{j % 5}',
                    'subreddit': f'subreddit_{j % 3}',
                    'score': j * 2,
                    'num_comments': j,
                    'created_utc': datetime.utcnow() - timedelta(hours=j),
                    'sentiment_score': (j % 100) / 100.0,
                    'relevance_score': ((j + 50) % 100) / 100.0
                }
&gt;               db_manager.add_mention(session_id, mention)
E               TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given

tests\test_performance.py:96: TypeError</failure></testcase><testcase classname="tests.test_performance.TestDatabasePerformance" name="test_concurrent_database_access" time="0.076"><failure message="AssertionError: Errors occurred: [{'worker_id': 0, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 3, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 2, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 1, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 4, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}]&#10;assert 5 == 0&#10; +  where 5 = len([{'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 0}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 3}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 2}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 1}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 4}])">self = &lt;tests.test_performance.TestDatabasePerformance object at 0x000002428DB1C890&gt;
db_manager = &lt;database.models.DatabaseManager object at 0x000002428DC2DB50&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DC2D8B0&gt;

    @pytest.mark.performance
    def test_concurrent_database_access(self, db_manager, performance_monitor):
        """Test concurrent database access performance."""
        results = []
        errors = []
    
        def worker_function(worker_id):
            try:
                session_id = db_manager.create_search_session(f"concurrent_perf_{worker_id}")
    
                # Each worker inserts 50 mentions
                for i in range(50):
                    mention = {
                        'reddit_id': f'concurrent_{worker_id}_{i}',
                        'title': f'Concurrent test {worker_id}_{i}',
                        'content': f'Content {worker_id}_{i}',
                        'author': f'user_{worker_id}',
                        'subreddit': 'concurrent_test',
                        'score': i,
                        'num_comments': i % 10,
                        'created_utc': datetime.utcnow(),
                        'sentiment_score': 0.5,
                        'relevance_score': 0.7
                    }
                    db_manager.add_mention(session_id, mention)
    
                # Query the data
                mentions = db_manager.get_mentions_by_session(session_id)
                results.append({
                    'worker_id': worker_id,
                    'mentions_count': len(mentions),
                    'session_id': session_id
                })
    
            except Exception as e:
                errors.append({'worker_id': worker_id, 'error': str(e)})
    
        performance_monitor.start()
    
        # Create and start threads
        threads = []
        num_workers = 5
    
        for i in range(num_workers):
            thread = threading.Thread(target=worker_function, args=(i,))
            threads.append(thread)
            thread.start()
    
        # Wait for completion
        for thread in threads:
            thread.join()
    
        metrics = performance_monitor.stop()
    
        # Verify results
&gt;       assert len(errors) == 0, f"Errors occurred: {errors}"
E       AssertionError: Errors occurred: [{'worker_id': 0, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 3, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 2, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 1, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}, {'worker_id': 4, 'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given'}]
E       assert 5 == 0
E        +  where 5 = len([{'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 0}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 3}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 2}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 1}, {'error': 'DatabaseManager.add_mention() takes 2 positional arguments but 3 were given', 'worker_id': 4}])

tests\test_performance.py:181: AssertionError</failure></testcase><testcase classname="tests.test_performance.TestScrapingPerformance" name="test_scraper_throughput" time="0.026"><failure message="TypeError: object of type 'coroutine' has no len()">self = &lt;tests.test_performance.TestScrapingPerformance object at 0x000002428DB1CB90&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DD04DD0&gt;

    @pytest.mark.performance
    def test_scraper_throughput(self, performance_monitor):
        """Test scraper throughput with mocked data."""
        scraper = RedditScraper(Mock())
    
        # Mock the scraping methods to return test data
        mock_mentions = []
        for i in range(100):
            mock_mentions.append({
                'reddit_id': f'throughput_test_{i}',
                'title': f'Throughput test post {i}',
                'content': f'Content for throughput test {i}',
                'author': f'user_{i}',
                'subreddit': 'test',
                'score': i,
                'num_comments': i % 20,
                'created_utc': datetime.utcnow(),
                'sentiment_score': 0.5,
                'relevance_score': 0.8
            })
    
        with patch.object(scraper, '_scrape_pattern') as mock_scrape:
            mock_scrape.return_value = mock_mentions
    
            performance_monitor.start()
    
            # Simulate processing multiple search patterns
            for i in range(5):
                results = scraper._scrape_pattern(
                    None, f"pattern_{i}", "test_term", 1, 1, None, None
                )
&gt;               assert len(results) == len(mock_mentions)
E               TypeError: object of type 'coroutine' has no len()

tests\test_performance.py:228: TypeError</failure></testcase><testcase classname="tests.test_performance.TestScrapingPerformance" name="test_rate_limiting_efficiency" time="0.027"><failure message="TypeError: 'Throttler' object does not support the context manager protocol">self = &lt;tests.test_performance.TestScrapingPerformance object at 0x000002428DB1CD10&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DFC43B0&gt;

    @pytest.mark.performance
    def test_rate_limiting_efficiency(self, performance_monitor):
        """Test rate limiting efficiency."""
        scraper = RedditScraper(Mock())
    
        performance_monitor.start()
    
        # Test multiple throttled operations
        for i in range(10):
&gt;           with scraper.throttler:
E           TypeError: 'Throttler' object does not support the context manager protocol

tests\test_performance.py:249: TypeError</failure></testcase><testcase classname="tests.test_performance.TestAnalyticsPerformance" name="test_metrics_calculation_performance" time="0.000"><failure message="TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'">self = &lt;tests.test_performance.TestAnalyticsPerformance object at 0x000002428DB1CEC0&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DFD8890&gt;

    @pytest.mark.performance
    def test_metrics_calculation_performance(self, performance_monitor):
        """Test metrics calculation performance."""
&gt;       analyzer = MetricsAnalyzer()
E       TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'

tests\test_performance.py:271: TypeError</failure></testcase><testcase classname="tests.test_performance.TestAnalyticsPerformance" name="test_data_validation_performance" time="49.102"><failure message="AssertionError: assert False&#10; +  where False = isinstance(QualityMetrics(total_records=2000, valid_records=1900, duplicate_records=71, spam_records=1200, low_quality_records=0, average_quality_score=0.8201815144082295, quality_distribution={&lt;DataQuality.FAIR: 'fair'&gt;: 40, &lt;DataQuality.GOOD: 'good'&gt;: 1960}, common_issues=[('not_in_whitelist', 2000), ('invalid_date_format', 2000), ('spam_pattern_repetitive', 1200), ('low_language_confidence', 841), ('missing_required_field', 300)]), dict)">self = &lt;tests.test_performance.TestAnalyticsPerformance object at 0x000002428DB1D040&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428DFD8F50&gt;

    @pytest.mark.performance
    def test_data_validation_performance(self, performance_monitor):
        """Test data validation performance."""
        validator = DataValidator()
    
        # Create dataset with various data quality issues
        test_dataset = []
    
        for i in range(2000):
            mention = {
                'reddit_id': f'validation_test_{i}',
                'title': f'Validation test post {i}' if i % 10 != 0 else '',  # Some empty titles
                'content': f'Content for validation test {i}' * (i % 5 + 1),  # Varying lengths
                'author': f'user_{i % 50}' if i % 20 != 0 else '',  # Some empty authors
                'subreddit': f'subreddit_{i % 10}',
                'score': i if i % 15 != 0 else -1,  # Some invalid scores
                'num_comments': i % 100,
                'created_utc': datetime.utcnow() - timedelta(hours=i % 100),
                'sentiment_score': (i % 200 - 100) / 100.0,
                'relevance_score': ((i + 50) % 100) / 100.0
            }
            test_dataset.append(mention)
    
        performance_monitor.start()
    
        # Validate dataset
        validated_mentions, quality_metrics = validator.validate_dataset(test_dataset)
    
        performance_metrics = performance_monitor.stop()
    
        # Verify validation results
        assert isinstance(validated_mentions, list)
&gt;       assert isinstance(quality_metrics, dict)
E       AssertionError: assert False
E        +  where False = isinstance(QualityMetrics(total_records=2000, valid_records=1900, duplicate_records=71, spam_records=1200, low_quality_records=0, average_quality_score=0.8201815144082295, quality_distribution={&lt;DataQuality.FAIR: 'fair'&gt;: 40, &lt;DataQuality.GOOD: 'good'&gt;: 1960}, common_issues=[('not_in_whitelist', 2000), ('invalid_date_format', 2000), ('spam_pattern_repetitive', 1200), ('low_language_confidence', 841), ('missing_required_field', 300)]), dict)

tests\test_performance.py:346: AssertionError</failure></testcase><testcase classname="tests.test_performance.TestVisualizationPerformance" name="test_chart_generation_performance" time="0.162"><failure message="AttributeError: 'MetricsVisualizer' object has no attribute 'create_comprehensive_dashboard'">self = &lt;tests.test_performance.TestVisualizationPerformance object at 0x000002428DB1D1F0&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002429238D610&gt;

    @pytest.mark.performance
    def test_chart_generation_performance(self, performance_monitor):
        """Test chart generation performance."""
        visualizer = MetricsVisualizer()
    
        # Create large dataset for visualization
        large_dataset = []
        subreddits = ['technology', 'programming', 'artificial', 'MachineLearning']
    
        for i in range(2000):
            mention = {
                'reddit_id': f'viz_test_{i}',
                'title': f'Visualization test post {i}',
                'content': f'Content {i}',
                'author': f'user_{i % 50}',
                'subreddit': subreddits[i % len(subreddits)],
                'score': i % 500,
                'num_comments': i % 50,
                'created_utc': datetime.utcnow() - timedelta(hours=i % 72),
                'sentiment_score': (i % 200 - 100) / 100.0,
                'relevance_score': ((i + 50) % 100) / 100.0
            }
            large_dataset.append(mention)
    
        performance_monitor.start()
    
        # Generate comprehensive dashboard
&gt;       dashboard = visualizer.create_comprehensive_dashboard(large_dataset)
E       AttributeError: 'MetricsVisualizer' object has no attribute 'create_comprehensive_dashboard'

tests\test_performance.py:388: AttributeError</failure></testcase><testcase classname="tests.test_performance.TestMemoryPerformance" name="test_memory_usage_during_processing" time="0.010"><failure message="TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given">self = &lt;tests.test_performance.TestMemoryPerformance object at 0x000002428DB1D3D0&gt;
db_manager = &lt;database.models.DatabaseManager object at 0x000002428FC414C0&gt;

    @pytest.mark.performance
    def test_memory_usage_during_processing(self, db_manager):
        """Test memory usage during large data processing."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
        # Create large dataset
        session_id = db_manager.create_search_session("memory_test")
    
        # Process data in batches to test memory efficiency
        batch_size = 100
        total_mentions = 1000
    
        for batch in range(total_mentions // batch_size):
            batch_mentions = []
    
            for i in range(batch_size):
                mention_id = batch * batch_size + i
                mention = {
                    'reddit_id': f'memory_test_{mention_id}',
                    'title': f'Memory test post {mention_id}',
                    'content': f'Content for memory test {mention_id}' * 10,  # Larger content
                    'author': f'user_{mention_id % 20}',
                    'subreddit': f'subreddit_{mention_id % 5}',
                    'score': mention_id,
                    'num_comments': mention_id % 50,
                    'created_utc': datetime.utcnow(),
                    'sentiment_score': 0.5,
                    'relevance_score': 0.7
                }
                batch_mentions.append(mention)
    
            # Process batch
            for mention in batch_mentions:
&gt;               db_manager.add_mention(session_id, mention)
E               TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given

tests\test_performance.py:439: TypeError</failure></testcase><testcase classname="tests.test_performance.TestMemoryPerformance" name="test_memory_leak_detection" time="0.000"><failure message="TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'">self = &lt;tests.test_performance.TestMemoryPerformance object at 0x000002428DB1D550&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428FBEE1E0&gt;

    @pytest.mark.performance
    def test_memory_leak_detection(self, performance_monitor):
        """Test for memory leaks during repeated operations."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
&gt;       analyzer = MetricsAnalyzer()
E       TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'

tests\test_performance.py:463: TypeError</failure></testcase><testcase classname="tests.test_performance.TestScalabilityLimits" name="test_maximum_concurrent_sessions" time="0.009"><failure message="TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given">self = &lt;tests.test_performance.TestScalabilityLimits object at 0x000002428DB1D610&gt;
db_manager = &lt;database.models.DatabaseManager object at 0x000002428FBEEC60&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428FBEF200&gt;

    @pytest.mark.performance
    def test_maximum_concurrent_sessions(self, db_manager, performance_monitor):
        """Test maximum number of concurrent sessions."""
        performance_monitor.start()
    
        session_ids = []
        max_sessions = 50
    
        # Create many concurrent sessions
        for i in range(max_sessions):
            session_id = db_manager.create_search_session(f"scalability_test_{i}")
            session_ids.append(session_id)
    
            # Add a few mentions to each session
            for j in range(5):
                mention = {
                    'reddit_id': f'scalability_{i}_{j}',
                    'title': f'Scalability test {i}_{j}',
                    'content': f'Content {i}_{j}',
                    'author': f'user_{i}',
                    'subreddit': 'scalability_test',
                    'score': j,
                    'num_comments': j,
                    'created_utc': datetime.utcnow(),
                    'sentiment_score': 0.5,
                    'relevance_score': 0.7
                }
&gt;               db_manager.add_mention(session_id, mention)
E               TypeError: DatabaseManager.add_mention() takes 2 positional arguments but 3 were given

tests\test_performance.py:531: TypeError</failure></testcase><testcase classname="tests.test_performance.TestScalabilityLimits" name="test_large_dataset_processing" time="0.000"><failure message="TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'">self = &lt;tests.test_performance.TestScalabilityLimits object at 0x000002428DB1D8B0&gt;
performance_monitor = &lt;tests.conftest.performance_monitor.&lt;locals&gt;.PerformanceMonitor object at 0x000002428FBEE480&gt;

    @pytest.mark.performance
    def test_large_dataset_processing(self, performance_monitor):
        """Test processing of very large datasets."""
&gt;       analyzer = MetricsAnalyzer()
E       TypeError: MetricsAnalyzer.__init__() missing 1 required positional argument: 'db_manager'

tests\test_performance.py:551: TypeError</failure></testcase></testsuite></testsuites>